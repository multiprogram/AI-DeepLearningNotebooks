{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"13_cifar_resnet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wJU2RPpSvlQT"},"source":["# CIFAR10を用いた物体認識（ResNet）\n","\n","\n","---\n","## 目的\n","CIFAR10 Datasetを用いて10クラスの物体認識を行う．プログラムの構成は，MNISTによる文字認識のプログラムと同様になっているため，基礎的な説明はそちらを参照して頂きたい．このページでは，MNISTによる文字認識のプログラムとの差分について書いていく．\n","\n","GPUを用いたネットワークの計算を行う．\n","また，Data Augmentationを用いた学習の効果について確認する．\n","ここでは畳み込みニューラルネットワークのモデルとして，ResNetを用いて実験を行う．"]},{"cell_type":"markdown","metadata":{"id":"5rQGfxWYK_4O"},"source":["## 準備\n","\n","### Google Colaboratoryの設定確認・変更\n","本チュートリアルではPyTorchを利用してニューラルネットワークの実装を確認，学習および評価を行います．\n","**GPUを用いて処理を行うために，上部のメニューバーの「ランタイム」→「ランタイムのタイプを変更」からハードウェアアクセラレータをGPUにしてください．**\n"]},{"cell_type":"markdown","metadata":{"id":"C2tsYagqvloK"},"source":["## 使用するデータセット\n","\n","### データセット\n","今回の物体認識では，CIFAR10データセットを用いる．CIFAR10データセットは，飛行機や犬などの10クラスの物体が表示されている画像から構成されたデータセットである．\n","\n","![CIFAR10_sample.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/176458/b6b43478-c85f-9211-7bc6-227d9b387af5.png)"]},{"cell_type":"markdown","metadata":{"id":"Xo4jjpmwvle1"},"source":["## モジュールのインポート\n","はじめに必要なモジュールをインポートする．\n","\n","### GPUの確認\n","GPUを使用した計算が可能かどうかを確認します．\n","\n","`GPU availability: True`と表示されれば，GPUを使用した計算をChainerで行うことが可能です．\n","Falseとなっている場合は，上記の「Google Colaboratoryの設定確認・変更」に記載している手順にしたがって，設定を変更した後に，モジュールのインポートから始めてください．\n"]},{"cell_type":"code","metadata":{"id":"iCeaCulfvlao"},"source":["# モジュールのインポート\n","from time import time\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import torchsummary\n","\n","# GPUの確認\n","use_cuda = torch.cuda.is_available()\n","print('Use CUDA:', use_cuda)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ppjeW5MbysXC"},"source":["## データセットの読み込みと確認\n","\n","学習データ（CIFAR10データセット）を読み込みます．\n","\n"]},{"cell_type":"code","metadata":{"id":"K_xx-TkVvls6"},"source":["transform_train = transforms.Compose([transforms.RandomCrop(32, padding=1),\n","                                      transforms.RandomHorizontalFlip(),\n","                                      transforms.ToTensor()])\n","transform_test = transforms.Compose([transforms.ToTensor()])\n","\n","train_data = torchvision.datasets.CIFAR10(root=\"./\", train=True, transform=transform_train, download=True)\n","test_data = torchvision.datasets.CIFAR10(root=\"./\", train=False, transform=transform_test, download=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xgDd3iX2zmSV"},"source":["## ネットワークモデルの定義\n","Residual Network (ResNet) を定義します．\n","\n","ResNetはBottleneckと呼ばれる構造から構成されています．\n","まず，`BottleNeck(nn.Module)`で，任意の形のBottleNeckを定義できるクラスを作成します．\n","`__init__`関数の引数である，`in_planes`は入力される特徴マップのチャンネル数，`planes`はBottleNeck内の特徴マップのチャンネル数を指定します．\n","\n","また，層を定義する`__init__`内では，`nn.Sequential()`という関数が用いられています．\n","これは，複数の層が格納されたリストを引数として受け取り，これらの層をひとまとめにしたオブジェクト（層）を定義する関数です・\n","下の関数では，畳み込みやBatchNormalizationがリスト内にされています．\n","`nn.Sequential`で定義した層`self.convs`では，実際に演算する際，すなわち`formward()`関数内では，`self.convs(x)`とすることで，リストに格納した演算をその順番通りに処理して返すことができます．\n","\n","上で定義したBottleNeck構造を活用して，ResNet（ここではResNet50）を定義します．\n","`ResNet`クラス内で定義されている`self._make_layer()`は，任意の形（総数）のResidual Block (複数のBottleNeck構造からなる層)を定義します．\n","Residual Blockに入力されるチャンネル数`planes`，BottleNeckの数`num_blocks`，畳み込みのストライド`stride`を指定します．\n","その後，それらの引数に従い，指定した数・パラメータのBottleNeckをリストないに格納します．\n","最後に，上で説明した`nn.Sequential`を用いて一塊の層として定義し，返すことで，任意の数の層を持つresidual blockを定義します．\n","\n","この`_make_layer()`を用いて，`__init__`でResNet全体を定義します．\n","`AdaptiveAvgPooling()`は任意のサイズの特徴マップに対して平均プーリングを適用する層です．\n","引数に`(1, 1)`を指定することで，どのようなサイズの特徴マップが入力された場合でも，1×1の特徴マップになるように平均プーリングを行います．\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"TNHnp_YczmY3"},"source":["class BottleNeck(nn.Module):\n","    expansion = 4\n","    def __init__(self, in_planes, planes, stride=1):\n","        super().__init__()\n","        self.convs = nn.Sequential(*[nn.Conv2d(in_planes, planes, kernel_size=1, bias=False),\n","                                     nn.BatchNorm2d(planes),\n","                                     nn.ReLU(inplace=True),\n","                                     nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False),\n","                                     nn.BatchNorm2d(planes),\n","                                     nn.ReLU(inplace=True),\n","                                     nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False),\n","                                     nn.BatchNorm2d(self.expansion * planes)])\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        out = self.convs(x)\n","        out += self.shortcut(x)\n","        out = self.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, n_class=10, n_blocks=[3, 4, 6, 3]):\n","        super().__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=0, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU()\n","        \n","        self.res1 = self._make_layer(64, n_blocks[0], stride=1)\n","        self.res2 = self._make_layer(128, n_blocks[1], stride=2)\n","        self.res3 = self._make_layer(256, n_blocks[2], stride=2)\n","        self.res4 = self._make_layer(512, n_blocks[3], stride=2)\n","        \n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(2048, n_class)\n","\n","    def _make_layer(self, planes, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(BottleNeck(self.in_planes, planes, stride))\n","            self.in_planes = planes * BottleNeck.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        h = self.relu(self.bn1(self.conv1(x)))\n","        h = self.res1(h)\n","        h = self.res2(h)\n","        h = self.res3(h)\n","        h = self.res4(h)\n","        h = self.avgpool(h)\n","        h = torch.flatten(h, 1)\n","        h = self.fc(h)\n","        return h\n","        \n","        \n","class ResNet50(ResNet):\n","    def __init__(self, n_class=10):\n","        super(ResNet50, self).__init__(n_class, n_blocks=[3, 4, 6, 3])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Dwuvfouzmd7"},"source":["## ネットワークの作成\n","上のプログラムで定義したネットワークを作成します．\n","\n","CNNクラスを呼び出して，ネットワークモデルを定義します． また，GPUを使う場合（use_cuda == True）には，ネットワークモデルをGPUメモリ上に配置します． これにより，GPUを用いた演算が可能となります．\n","\n","学習を行う際の最適化方法としてモーメンタムSGD(モーメンタム付き確率的勾配降下法）を利用します． また，学習率を0.01，モーメンタムを0.9として引数に与えます．\n","\n","最後に，定義したネットワークの詳細情報を`torchsummary.summary()`関数を用いて表示します．"]},{"cell_type":"code","metadata":{"id":"23m79Eq-zmjl"},"source":["model = ResNet50(n_class=10)\n","if use_cuda:\n","    model.cuda()\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","# モデルの情報を表示\n","torchsummary.summary(model, (3, 32, 32))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MUNa9Xe79vAG"},"source":["## 学習\n","１回の誤差を算出するデータ数（ミニバッチサイズ）を128，学習エポック数を100とします．\n","CIFAR10の学習データサイズを取得し，１エポック内における更新回数を求めます．\n","学習モデルに`image`を与えて各クラスの確率yを取得します．各クラスの確率yと教師ラベル`label`との誤差をsoftmax coross entropy誤差関数で算出します．\n","また，認識精度も算出します．そして，誤差をbackward関数で逆伝播し，ネットワークの更新を行います．"]},{"cell_type":"code","metadata":{"id":"68RE3RTa76-W"},"source":["# ミニバッチサイズ・エポック数の設定\n","batch_size = 128\n","epoch_num = 10\n","n_iter = len(train_data) / batch_size\n","\n","# データローダーの設定\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n","\n","# 誤差関数の設定\n","criterion = nn.CrossEntropyLoss()\n","if use_cuda:\n","    criterion.cuda()\n","\n","# ネットワークを学習モードへ変更\n","model.train()\n","\n","start = time()\n","for epoch in range(1, epoch_num+1):\n","    sum_loss = 0.0\n","    count = 0\n","    \n","    for image, label in train_loader:\n","        if use_cuda:\n","            image = image.cuda()\n","            label = label.cuda()\n","\n","        y = model(image)\n","        loss = criterion(y, label)\n","        \n","        model.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        sum_loss += loss.item()\n","        \n","        pred = torch.argmax(y, dim=1)\n","        count += torch.sum(pred == label)\n","\n","    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n","                                                                                 sum_loss / n_iter,\n","                                                                                 count.item() / len(train_loader),\n","                                                                                 time() - start))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"119eIrSmzmw6"},"source":["## テスト\n","学習したネットワークモデルを用いて評価を行います．"]},{"cell_type":"code","metadata":{"id":"yoYVMRGLzm1I"},"source":["# データローダーの準備\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False)\n","\n","# ネットワークを評価モードへ変更\n","model.eval()\n","\n","# 評価の実行\n","count = 0\n","with torch.no_grad():\n","    for image, label in test_loader:\n","\n","        if use_cuda:\n","            image = image.cuda()\n","            label = label.cuda()\n","            \n","        y = model(image)\n","\n","        pred = torch.argmax(y, dim=1)\n","        count += torch.sum(pred == label)\n","\n","print(\"test accuracy: {}\".format(count.item() / 10000.))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_U8wsW37hUUI"},"source":["## 課題\n","\n","\n","### 1. 学習の設定を変更し，認識精度の変化を確認しましょう．\n","\n","**ヒント：プログラムの中で変更で切る設定は次のようなものが存在します．**\n","* ミニバッチサイズ\n","* 学習回数（Epoch数）\n","* 学習率\n","* 最適化手法\n","  * `torch.optim.Adagrad()`や`torch.optim.Adam()`などが考えられます．\n","  * PyTorchで使用できる最適化手法は[こちらのページ](https://pytorch.org/docs/stable/optim.html#algorithms)にまとめられています．\n","\n","\n","### 2. Data Augmentationの種類を追加して学習を行いましょう．\n","\n","**ヒント**\n","：学習時に使用するData Augmentationは`transform_train`の部分で変更できます．\n","\n","```python\n","transform_train = transforms.Compose([(この部分に使用するAugmentationの処理を追加) ,\n","                                      transforms.ToTensor(),\n","                                      transforms.LinearTransformation(Z, mean)])\n","```\n","\n","PyTorch（torchvision）で使用可能な変換は[こちらのページ](https://pytorch.org/docs/stable/torchvision/transforms.html)にまとめられています．\n"]}]}