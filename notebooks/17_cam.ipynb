{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"17_cam.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"vQfhYcVF8KPt"},"source":["# CNNの可視化 (Class Activation Mapping; CAM)\n","\n","---\n","\n","## 目的\n","Class Activation Mapping (CAM)の仕組みを理解する.\n","\n","CAMを用いてCIFAR-10データセットに対するネットワークの判断根拠の可視化を行う．\n","\n","## Class Activation Mapping (CAM)\n","Class Activation Mapping (CAM)[1]とは，ネットワークの出力に対する全結合層の結合重みを用いて，ネットワークの推論時における貢献度の高い領域をClass Activation Map (Attention map) として可視化することができる手法です．\n","CAMでは，最後の畳み込み層の後にGlobal Average Pooling (GAP)[2]を行い，特徴マップのチャネル数を全結合層のユニット数にする必要があります．\n","GAPとは，Kチャネルの特徴マップにおいて，各チャネルごとに平均値を算出し，その平均値を各特徴マップの値とする処理です．\n","これにより，全結合層におけるパラメタ数を大幅に削減することができます．\n","その後，畳み込み層で得られたKチャネルの特徴マップとクラスCに対応する全結合層\n","の結合重みを用いることで，各クラスにおけるAttention mapを獲得します．\n","<img src=\"https://www.dropbox.com/s/vjhai6vxvqgkkms/cam.png?dl=1\" width=100%>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"V8ehSX6U8KPv"},"source":["## モジュールのインポート\n","プログラムの実行に必要なモジュールをインポートします．"]},{"cell_type":"code","metadata":{"id":"VaNXqInW8KPv"},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.backends.cudnn as cudnn\n","import torchsummary"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b4gEy7cGCfz8"},"source":["## GPUの確認\n","GPUを使用した計算が可能かどうかを確認します．\n","下記のコードを実行してGPU情報を確認します． GPUの確認を行うためには，上部のメニューバーの「ランタイム」→「ランタイムのタイプを変更」からハードウェアアクセラレータをGPUにしてください．\n","\n","`Use CUDA: True`と表示されれば，GPUを使用した計算をPytorchで行うことが可能です． CPUとなっている場合は，上記に記載している手順にしたがって，設定を変更してください．"]},{"cell_type":"code","metadata":{"id":"p9fjeG_U8KP1"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","use_cuda = torch.cuda.is_available()\n","cudnn.benchmark = True\n","print('Use CUDA:', use_cuda)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uanw74k0F9iw"},"source":["下記のコードを実行してGPU情報を確認します．\n","\n"]},{"cell_type":"code","metadata":{"id":"eeUIUazLGGPu"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QEgbYa9Elo