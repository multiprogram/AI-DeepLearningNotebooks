
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "18_grad_cam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQfhYcVF8KPt"
      },
      "source": [
        "# CNNの可視化 (Gradient-weighted Class Activation Mapping; Grad-CAM)\n",
        "\n",
        "---\n",
        "\n",
        "## 目的\n",
        "Gradient-weighted Class Activation Mapping (Grad-CAM)の仕組みを理解する.\n",
        "\n",
        "Grad-CAMを用いてCIFAR-10データセットに対するネットワークの判断根拠の可視化を行う．\n",
        "\n",
        "## Gradient-weighted Class Activation Mapping (Grad-CAM)\n",
        "Grad-CAM[1]は，逆伝播時の正値の勾配を用いることでCNNを可視化する手法です．\n",
        "Grad-CAMは，逆伝播時の特定のクラスにおける勾配をGlobal Average Pooling (GAP)[2]により空間方向に対する平均値を求め，各特徴マップに対する重みとします．\n",
        "その後，獲得した重みを各特徴マップに重み付けすることでAttention map を獲得します．\n",
        "02_CAM.ipynbで使用したClass Activation Mapping (CAM)[3]は，ネットワークの一部をGAPに置き換える必要があるため，Attention mapを獲得するためにネットワークを学習させる必要があります．一方で，Grad-CAMはネットワークの順伝播時の特徴マップと逆伝播時の勾配を用いてAttention mapを獲得します．そのため，学習済みの様々なネットワークからAttention map を獲得することができます．\n",
        "\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/x23sm70ftoo7caa/grad-cam.png?dl=1\" width = 100%>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwB6Pj1BoGRo"
      },
      "source": [
        "## pytorch-gradcamのインストール\n",
        "\n",
        "Grad-CAMを利用するために必要なツールをインストールします．\n",
        "Grad-CAMは，`pytorch-gradcam`というツールをインストールすることで簡単に利用することができます．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmCnC2cqoGpC"
      },
      "source": [
        "!pip install pytorch-gradcam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8ehSX6U8KPv"
      },
      "source": [
        "## モジュールのインポート\n",
        "プログラムの実行に必要なモジュールをインポートします．\n",
        "今回はPyTorchのライブラリに加えて，\n",
        "上でインストールしたpytorch-gradcam (`gradcam`) もインポートします．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaNXqInW8KPv"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models\n",
        "\n",
        "import torchsummary\n",
        "\n",
        "from gradcam import GradCAM\n",
        "from gradcam.utils import visualize_cam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4gEy7cGCfz8"
      },
      "source": [
        "## GPUの確認\n",
        "GPUを使用した計算が可能かどうかを確認します．\n",
        "下記のコードを実行してGPU情報を確認します． GPUの確認を行うためには，上部のメニューバーの「ランタイム」→「ランタイムのタイプを変更」からハードウェアアクセラレータをGPUにしてください．\n",
        "\n",
        "`Use CUDA: True`と表示されれば，GPUを使用した計算をPytorchで行うことが可能です． CPUとなっている場合は，上記に記載している手順にしたがって，設定を変更してください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9fjeG_U8KP1"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Use Device:', device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XzIClJ5k6h4"
      },
      "source": [
        "## 使用するデータセット\n",
        "\n",
        "### データセット\n",
        "今回の物体認識では，CIFAR-10データセットを使用します．CIFAR-10データセットは，飛行機や犬などの10クラスの物体が表示されている画像から構成されたデータセットです．\n",
        "\n",
        "![CIFAR10_sample.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/176458/b6b43478-c85f-9211-7bc6-227d9b387af5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNzvYQL58KP4"
      },
      "source": [
        "### データセットのダウンロードと読み込み\n",
        "実験に使用するCIFAR-10データセットを読み込みます．\n",
        "１回の誤差を算出するデータ数 (ミニバッチサイズ) は，64とします．\n",
        "まず，CIFAR-10データセットをダウンロードします．\n",
        "次に，ダウンロードしたデータセットを読み込みます．\n",
        "学習には，大量のデータを利用しますが，それでも十分ではありません． そこで，データ拡張 (data augmentation) により，データのバリエーションを増やします． 一般的な方法は，画像の左右反転，明るさ変換などです．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leWJTOIL8KP4"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Scale(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=20)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=20)\n",
        "\n",
        "classes_list = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFCekfs78KQC"
      },
      "source": [
        "## ネットワークモデルの定義\n",